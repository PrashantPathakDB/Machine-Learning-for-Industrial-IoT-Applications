{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "data_test \u003d utils.load_data(\u0027data/test_FD004.txt\u0027)\n\nes_test, _ \u003d make_entityset(data_test, nclusters, kmeans\u003dkmeans)\nfm_test \u003d ft.calculate_feature_matrix(entityset\u003des_test, features\u003dfeatures, verbose\u003dTrue, chunk_size\u003d\u0027cutoff time\u0027)\nX \u003d fm_test.copy().fillna(0)\ny \u003d pd.read_csv(\u0027data/RUL_FD004.txt\u0027, sep\u003d\u0027 \u0027, header\u003d-1, names\u003d[\u0027RUL\u0027], index_col\u003dFalse)\npreds \u003d regs[0].predict(X)\nprint(\u0027Mean Abs Error: {:.2f}\u0027.format(mean_absolute_error(preds, y)))\n\n\nfrom btb import HyperParameter, ParamTypes\nfrom btb.tuning import GP\n\ndef run_btb(fm_list, n\u003d30):\n    hyperparam_ranges \u003d [\n            (\u0027n_estimators\u0027, HyperParameter(ParamTypes.INT, [10, 200])),\n            (\u0027max_feats\u0027, HyperParameter(ParamTypes.INT, [5, 50])),\n            (\u0027nfeats\u0027, HyperParameter(ParamTypes.INT, [10, 70])),\n    ]\n    tuner \u003d GP(hyperparam_ranges)\n\n    tested_parameters \u003d np.zeros((n, len(hyperparam_ranges)), dtype\u003dobject)\n    scores \u003d []\n    \n    print(\u0027[n_est, max_feats, nfeats]\u0027)\n    best \u003d 45\n\n    for i in tqdm(range(n)):\n        hyperparams \u003d tuner.propose()\n        cvscores, regs, selectors \u003d pipeline_for_test(fm_list, hyperparams\u003dhyperparams, do_selection\u003dTrue)\n        bound \u003d np.mean(cvscores)\n        tested_parameters[i, :] \u003d hyperparams\n        tuner.add(hyperparams, -np.mean(cvscores))\n        if np.mean(cvscores) + np.std(cvscores) \u003c best:\n            best \u003d np.mean(cvscores)\n            best_hyperparams \u003d hyperparams\n            best_reg \u003d regs[0]\n            best_sel \u003d selectors[0]\n            print(\u0027{}. {} -- Average MAE: {:.1f}, Std: {:.2f}\u0027.format(i, \n                                                                      best_hyperparams, \n                                                                      np.mean(cvscores), \n                                                                      np.std(cvscores)))\n            print(\u0027Raw: {}\u0027.format([float(\u0027{:.1f}\u0027.format(s)) for s in cvscores]))\n\n    return best_hyperparams, (best_sel, best_reg)\n\nbest_hyperparams, best_pipeline \u003d run_btb(fm_list, n\u003d30)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Abs Error on Test: 29.48\n",
            "1: MAX(recordings.sensor_measurement_13) [0.139]\n",
            "2: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_13)) [0.104]\n",
            "3: MAX(recordings.sensor_measurement_11) [0.084]\n",
            "4: MAX(recordings.settings_clusters.LAST(recordings.sensor_measurement_11)) [0.083]\n",
            "5: COMPLEXITY(recordings.settings_clusters.LAST(recordings.sensor_measurement_8)) [0.071]\n",
            "-----\n",
            "\n"
          ]
        }
      ],
      "source": "X \u003d fm_test.copy().fillna(0)\ny \u003d pd.read_csv(\u0027data/RUL_FD004.txt\u0027, sep\u003d\u0027 \u0027, header\u003d-1, names\u003d[\u0027RUL\u0027], index_col\u003dFalse)\n\npreds \u003d best_pipeline[1].predict(best_pipeline[0].transform(X))\nscore \u003d mean_absolute_error(preds, y)\nprint(\u0027Mean Abs Error on Test: {:.2f}\u0027.format(score))\nmost_imp_feats \u003d utils.feature_importances(X.iloc[:, best_pipeline[0].support_], best_pipeline[1])\n\nfrom featuretools.primitives import Min\nold_fm, features \u003d ft.dfs(entityset\u003des, \n                      target_entity\u003d\u0027engines\u0027,\n                      agg_primitives\u003d[\u0027last\u0027, \u0027max\u0027, \u0027min\u0027],\n                      trans_primitives\u003d[],\n                      cutoff_time\u003dcutoff_time_list[0],\n                      max_depth\u003d3,\n                      verbose\u003dTrue)\n\nold_fm_list \u003d [old_fm]\nfor i in tqdm(range(1, splits)):\n    old_fm \u003d ft.calculate_feature_matrix(entityset\u003dmake_entityset(data, nclusters, kmeans\u003dkmeans)[0], \n                                     features\u003dfeatures, \n                                     cutoff_time\u003dcutoff_time_list[i])\n    old_fm_list.append(fm)\n\nold_scores \u003d []\nmedian_scores \u003d []\nfor fm in old_fm_list:\n    X \u003d fm.copy().fillna(0)\n    y \u003d X.pop(\u0027RUL\u0027)\n    X_train, X_test, y_train, y_test \u003d train_test_split(X, y)\n    reg \u003d RandomForestRegressor(n_estimators\u003d10)\n    reg.fit(X_train, y_train)\n    preds \u003d reg.predict(X_test)\n    old_scores.append(mean_absolute_error(preds, y_test))\n    \n    medianpredict \u003d [np.median(y_train) for _ in y_test]\n    median_scores.append(mean_absolute_error(medianpredict, y_test))\n\nprint([float(\u0027{:.1f}\u0027.format(score)) for score in old_scores])\nprint(\u0027Average MAE: {:.2f}, Std: {:.2f}\\n\u0027.format(np.mean(old_scores), np.std(old_scores)))\n\nprint([float(\u0027{:.1f}\u0027.format(score)) for score in median_scores])\nprint(\u0027Baseline by Median MAE: {:.2f}, Std: {:.2f}\\n\u0027.format(np.mean(median_scores), np.std(median_scores)))"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[49.5, 52.8, 49.0, 49.5, 48.3]\n",
            "Baseline by Median MAE: 49.82, Std: 1.58\n",
            "\n"
          ]
        }
      ],
      "source": "y \u003d pd.read_csv(\u0027data/RUL_FD004.txt\u0027, sep\u003d\u0027 \u0027, header\u003d-1, names\u003d[\u0027RUL\u0027], index_col\u003dFalse)\nmedian_scores_2 \u003d []\nfor ct in cutoff_time_list:\n    medianpredict2 \u003d [np.median(ct[\u0027RUL\u0027].values) for _ in y.values]\n    median_scores_2.append(mean_absolute_error(medianpredict2, y))\nprint([float(\u0027{:.1f}\u0027.format(score)) for score in median_scores_2])\nprint(\u0027Baseline by Median MAE: {:.2f}, Std: {:.2f}\\n\u0027.format(np.mean(median_scores_2), np.std(median_scores_2)))\n\n\nimport os\n\ntry:\n    os.mkdir(\"output\")\nexcept:\n    pass\n\nfm.to_csv(\u0027output/advanced_train_feature_matrix.csv\u0027)\ncutoff_time_list[0].to_csv(\u0027output/advanced_train_label_times.csv\u0027)\nfm_test.to_csv(\u0027output/advanced_test_feature_matrix.csv\u0027)\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "\nimport numpy as np\nimport pandas as pd\nimport featuretools as ft\nimport utils\n\ndata_path \u003d \u0027data/train_FD004.txt\u0027\ndata \u003d utils.load_data(data_path)\n\ndata.head()\n\nfrom tqdm import tqdm\n\nsplits \u003d 5\ncutoff_time_list \u003d []\n\nfor i in tqdm(range(splits)):\n    cutoff_time_list.append(utils.make_cutoff_times(data))\n\ncutoff_time_list[0].head()\n\nfrom sklearn.cluster import KMeans\n\nnclusters \u003d 50\n\ndef make_entityset(data, nclusters, kmeans\u003dNone):\n    X \u003d data[[\u0027operational_setting_1\u0027, \u0027operational_setting_2\u0027, \u0027operational_setting_3\u0027]]\n    if kmeans:\n        kmeans\u003dkmeans\n    else:\n        kmeans \u003d KMeans(n_clusters\u003dnclusters).fit(X)\n    data[\u0027settings_clusters\u0027] \u003d kmeans.predict(X)\n    \n    es \u003d ft.EntitySet(\u0027Dataset\u0027)\n    es.entity_from_dataframe(dataframe\u003ddata,\n                             entity_id\u003d\u0027recordings\u0027,\n                             index\u003d\u0027index\u0027,\n                             time_index\u003d\u0027time\u0027)\n\n    es.normalize_entity(base_entity_id\u003d\u0027recordings\u0027, \n                        new_entity_id\u003d\u0027engines\u0027,\n                        index\u003d\u0027engine_no\u0027)\n    \n    es.normalize_entity(base_entity_id\u003d\u0027recordings\u0027, \n                        new_entity_id\u003d\u0027settings_clusters\u0027,\n                        index\u003d\u0027settings_clusters\u0027)\n    \n    return es, kmeans\nes, kmeans \u003d make_entityset(data, nclusters)\nes\n\nes.plot()\n\nfrom featuretools.primitives import make_agg_primitive\nimport featuretools.variable_types as vtypes\n\nfrom tsfresh.feature_extraction.feature_calculators import (number_peaks, mean_abs_change, \n                                                            cid_ce, last_location_of_maximum, length)\n\n\nComplexity \u003d make_agg_primitive(lambda x: cid_ce(x, False),\n                              input_types\u003d[vtypes.Numeric],\n                              return_type\u003dvtypes.Numeric,\n                              name\u003d\"complexity\")\n\nfm, features \u003d ft.dfs(entityset\u003des, \n                      target_entity\u003d\u0027engines\u0027,\n                      agg_primitives\u003d[\u0027last\u0027, \u0027max\u0027, Complexity],\n                      trans_primitives\u003d[],\n                      chunk_size\u003d.26,\n                      cutoff_time\u003dcutoff_time_list[0],\n                      max_depth\u003d3,\n                      verbose\u003dTrue)\n\nfm.to_csv(\u0027advanced_fm.csv\u0027)\nfm.head()\n\nfm_list \u003d [fm]\nfor i in tqdm(range(1, splits)):\n    fm \u003d ft.calculate_feature_matrix(entityset\u003dmake_entityset(data, nclusters, kmeans\u003dkmeans)[0], \n                                     features\u003dfeatures, \n                                     chunk_size\u003d.26, \n                                     cutoff_time\u003dcutoff_time_list[i])\n    fm_list.append(fm)\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.feature_selection import RFE\ndef pipeline_for_test(fm_list, hyperparams\u003d{\u0027n_estimators\u0027:100, \u0027max_feats\u0027:50, \u0027nfeats\u0027:50}, do_selection\u003dFalse):\n    scores \u003d []\n    regs \u003d []\n    selectors \u003d []\n    for fm in fm_list:\n        X \u003d fm.copy().fillna(0)\n        y \u003d X.pop(\u0027RUL\u0027)\n        reg \u003d RandomForestRegressor(n_estimators\u003dint(hyperparams[\u0027n_estimators\u0027]), \n                                    max_features\u003dmin(int(hyperparams[\u0027max_feats\u0027]), \n                                                     int(hyperparams[\u0027nfeats\u0027])))\n        X_train, X_test, y_train, y_test \u003d train_test_split(X, y)\n        if do_selection:\n            reg2 \u003d RandomForestRegressor(n_estimators\u003d10, n_jobs\u003d3)\n            selector \u003d RFE(reg2, int(hyperparams[\u0027nfeats\u0027]), step\u003d25)\n            selector.fit(X_train, y_train)\n            X_train \u003d selector.transform(X_train)\n            X_test \u003d selector.transform(X_test)\n            selectors.append(selector)\n        reg.fit(X_train, y_train)\n        regs.append(reg)\n        \n        preds \u003d reg.predict(X_test)\n        scores.append(mean_absolute_error(preds, y_test))\n    return scores, regs, selectors    \nscores, regs, selectors \u003d pipeline_for_test(fm_list)\nprint([float(\u0027{:.1f}\u0027.format(score)) for score in scores])\nprint(\u0027Average MAE: {:.1f}, Std: {:.2f}\\n\u0027.format(np.mean(scores), np.std(scores)))\n\nmost_imp_feats \u003d utils.feature_importances(fm_list[0], regs[0])",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}